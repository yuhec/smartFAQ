{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# TRAINING \n---\n## IMPORT ",
      "metadata": {
        "tags": [],
        "cell_id": "00000-d5770c34-113c-4c2d-8b1b-4a0d82dd4300",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 2748,
        "execution_start": 1614956805767,
        "source_hash": "eddf3931",
        "tags": [],
        "cell_id": "00001-a5c17778-4cad-425a-8bac-6aa989da1b65",
        "deepnote_cell_type": "code"
      },
      "source": "import pickle\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom tensorflow.python.keras import models\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import TensorBoard\n\nimport os",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Load Data",
      "metadata": {
        "tags": [],
        "cell_id": "00002-cd19217e-9460-450c-b686-43fbabcb2b35",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 3778,
        "execution_start": 1614956811688,
        "source_hash": "4cae02c2",
        "tags": [],
        "cell_id": "00003-47afa398-f085-403c-a47e-a9955abb19eb",
        "deepnote_cell_type": "code"
      },
      "source": "with open('../data/x_train.pickle', 'rb') as handle:\n    X_train = pickle.load(handle)\nwith open('../data/y_train.pickle', 'rb') as handle:\n    y_train = pickle.load(handle)\nwith open('../data/x_val.pickle', 'rb') as handle:\n    X_val = pickle.load(handle)\nwith open('../data/y_val.pickle', 'rb') as handle:\n    y_val = pickle.load(handle)",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 49,
        "execution_start": 1614956817555,
        "source_hash": "c085b6ba",
        "tags": [],
        "cell_id": "00004-96e87d3f-2986-4878-a67b-c1008f3481f8",
        "deepnote_cell_type": "code"
      },
      "source": "X_train.head()",
      "execution_count": 28,
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>question</th>\n      <th>question_body</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>490144</th>\n      <td>21032057</td>\n      <td>Deleting multiple indexes list python</td>\n      <td>My problem I list eg lst lst pop lst pop Becau...</td>\n      <td>You use list comprehension rebuild list indice...</td>\n    </tr>\n    <tr>\n      <th>815071</th>\n      <td>34022443</td>\n      <td>Django Grappelli Nested Inlines create new nes...</td>\n      <td>I looking way create new nested row saving own...</td>\n      <td>What take templates django grappelli inline pr...</td>\n    </tr>\n    <tr>\n      <th>62146</th>\n      <td>2185875</td>\n      <td>Expanding elements list</td>\n      <td>I 'm looking nice way process list elements ne...</td>\n      <td>The last one probably pythonic could try impli...</td>\n    </tr>\n    <tr>\n      <th>304024</th>\n      <td>12626260</td>\n      <td>UnicodeDecodeError processing filenames</td>\n      <td>I 'm using Python Ubuntu x I files folder file...</td>\n      <td>Your filenames byte strings contain UTF bytes ...</td>\n    </tr>\n    <tr>\n      <th>187856</th>\n      <td>7288407</td>\n      <td>Python string manipulation performance problems</td>\n      <td>I following piece code I execute around millio...</td>\n      <td>EDIT I 'm changing answer bit I 'll leave orig...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "              id                                           question  \\\n490144  21032057              Deleting multiple indexes list python   \n815071  34022443  Django Grappelli Nested Inlines create new nes...   \n62146    2185875                            Expanding elements list   \n304024  12626260            UnicodeDecodeError processing filenames   \n187856   7288407    Python string manipulation performance problems   \n\n                                            question_body  \\\n490144  My problem I list eg lst lst pop lst pop Becau...   \n815071  I looking way create new nested row saving own...   \n62146   I 'm looking nice way process list elements ne...   \n304024  I 'm using Python Ubuntu x I files folder file...   \n187856  I following piece code I execute around millio...   \n\n                                                   answer  \n490144  You use list comprehension rebuild list indice...  \n815071  What take templates django grappelli inline pr...  \n62146   The last one probably pythonic could try impli...  \n304024  Your filenames byte strings contain UTF bytes ...  \n187856  EDIT I 'm changing answer bit I 'll leave orig...  "
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 747,
        "execution_start": 1614956823073,
        "source_hash": "a5ed259c",
        "tags": [],
        "cell_id": "00005-2837c958-6be5-47b5-9910-61e0b16f51ac",
        "deepnote_cell_type": "code"
      },
      "source": "# Mean length of body x and y\navg_question = sum(len(word) for word in X_train['question']) / len(X_train['question'])\navg_question_body = sum(len(word) for word in X_train['question_body']) / len(X_train['question_body'])\navg_answer = sum(len(word) for word in X_train['answer']) / len(X_train['answer'])\nprint(avg_question)\nprint(avg_question_body)\nprint(avg_answer)",
      "execution_count": 29,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "40.827\n718.1521\n414.0572\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Preprocessing",
      "metadata": {
        "tags": [],
        "cell_id": "00006-91e6a4ae-48d6-4093-ba62-b65fbf905c5a",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 0,
        "execution_start": 1614957289741,
        "source_hash": "df800b13",
        "tags": [],
        "cell_id": "00007-c0ad64ea-8c2f-4b17-bc78-898af9c00978",
        "deepnote_cell_type": "code"
      },
      "source": "def vectorize_data(X_train, X_val, max_features=1000):    \n    vectorizer = CountVectorizer(max_features=max_features)\n\n#     X_train_vect = X_train\n#     X_test_vect = X_test\n\n#     X_train_vect['Title'] = vectorizer.fit_transform(X_train_vect['Title'])\n#     X_test_vect['Title'] = vectorizer.transform(X_test_vect['Title'])\n\n#     X_train_vect['Body_x'] = vectorizer.fit_transform(X_train_vect['Body_x'])\n#     X_test_vect['Body_x'] = vectorizer.transform(X_test_vect['Body_x'])\n\n#     X_train_vect['Body_y'] = vectorizer.fit_transform(X_train_vect['Body_y'])\n#     X_test_vect['Body_y'] = vectorizer.transform(X_test_vect['Body_y'])\n\n    X_train_vect = vectorizer.fit_transform(X_train)\n    X_val_vect = vectorizer.transform(X_val)\n\n    return X_train_vect, X_val_vect",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 0,
        "execution_start": 1614957291920,
        "source_hash": "f70cbd92",
        "tags": [],
        "cell_id": "00008-ee8d6c5c-d528-40a7-bc4e-98283530c326",
        "deepnote_cell_type": "code"
      },
      "source": "X_train_vect, X_test_vect = vectorize_data(X_train['answer'], X_val['answer'], max_features=1000)",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 0,
        "execution_start": 1614956827621,
        "is_code_hidden": false,
        "source_hash": "291e2db8",
        "tags": [],
        "cell_id": "00009-99c1c92d-9939-48a4-a358-a0638760596b",
        "deepnote_cell_type": "code"
      },
      "source": "# MÃªme longeur de texte\n# maxlenBodyX = 750\n# maxlenBodyY = 750\n# maxLenTitle = 60\n\n# x_train_pad = X_train_vect\n# x_test_pad = X_test_vect\n\n# x_train_pad['Title'] = sequence.pad_sequences(x_train_pad['Title'], maxLenTitle)\n# x_train_pad['Body_x'] = sequence.pad_sequences(x_train_pad['Body_x'], maxlenBodyX)\n# x_train_pad['Body_y'] = sequence.pad_sequences(x_train_pad['Body_y'], maxlenBodyY)\n\n# x_test_pad['Title'] = sequence.pad_sequences(x_test_pad['Title'], maxLenTitle)\n# x_test_pad['Body_x'] = sequence.pad_sequences(x_test_pad['Body_x'], maxlenBodyX)\n# x_test_pad['Body_y'] = sequence.pad_sequences(x_test_pad['Body_y'], maxlenBodyY)\n",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Create model",
      "metadata": {
        "tags": [],
        "cell_id": "00010-f8deb02c-cd88-49c1-b13e-b6a979d376cd",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 0,
        "execution_start": 1614957115391,
        "source_hash": "476c5132",
        "tags": [],
        "cell_id": "00011-6dd8a50b-6386-4063-bc24-0f2272272fa7",
        "deepnote_cell_type": "code"
      },
      "source": "def build_model(input_shape, DROPOUT_RATE = 0.2, UNITS = 64, NUM_CLASSES = 2):\n\n    model = keras.Sequential()\n    model.add(Dense(units=50, activation='relu'))\n    model.add(Dense(units=1, activation='sigmoid'))\n    model.build(input_shape)\n    model.summary()\n    return model",
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 10,
        "execution_start": 1614957202971,
        "source_hash": "fe46666f",
        "tags": [],
        "cell_id": "00012-859e96d9-bbde-4b8d-bae1-4b28abd5c85f",
        "deepnote_cell_type": "code"
      },
      "source": "X_train_vect[0].shape[1]",
      "execution_count": 34,
      "outputs": [
        {
          "data": {
            "text/plain": "1000"
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 10,
        "execution_start": 1614957130886,
        "source_hash": "c31c8209",
        "tags": [],
        "cell_id": "00013-7a05a6da-8715-451f-a895-a346a0731180",
        "deepnote_cell_type": "code"
      },
      "source": "model = build_model(X_train_vect.shape)",
      "execution_count": 35,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_2 (Dense)              (10000, 50)               50050     \n_________________________________________________________________\ndense_3 (Dense)              (10000, 1)                51        \n=================================================================\nTotal params: 50,101\nTrainable params: 50,101\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Compilation",
      "metadata": {
        "tags": [],
        "cell_id": "00014-95ad4958-dd3c-41e1-ba6c-c9ca49e3664b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": true,
        "execution_millis": 3,
        "source_hash": "d4d2218e",
        "tags": [],
        "cell_id": "00015-89e07e6e-e0f6-424f-88b2-73f624db5621",
        "deepnote_cell_type": "code"
      },
      "source": "INIT_LR = 0.001\nEPOCHS = 10",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": true,
        "execution_millis": 2,
        "source_hash": "6e8ca5fc",
        "tags": [],
        "cell_id": "00016-da718e3a-05ba-4cb6-94d9-161f946e5039",
        "deepnote_cell_type": "code"
      },
      "source": "optimizer = Adam(learning_rate=INIT_LR, decay=INIT_LR/EPOCHS)",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": true,
        "execution_millis": 8,
        "source_hash": "635ba474",
        "tags": [],
        "cell_id": "00017-cbd3ad2a-c0d2-4b93-b585-f114984f95f7",
        "deepnote_cell_type": "code"
      },
      "source": "model.compile(\n  optimizer = optimizer,\n  loss = \"binary_crossentropy\",\n  metrics = [\"accuracy\"]\n)",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Entrainement",
      "metadata": {
        "tags": [],
        "cell_id": "00018-1d81beba-c36a-4cd5-bc8f-f71ae5de9d89",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": true,
        "execution_millis": 1,
        "source_hash": "847f7517",
        "tags": [],
        "cell_id": "00019-ccbc6bf8-3555-40bf-88b8-b5148b110fc0",
        "deepnote_cell_type": "code"
      },
      "source": "def train_model(X_train, y_train, EPOCHS = 100, BATCH_SIZE = 128, patience=5):\n    # For tensorboard\n#     os.makedirs(\"./logs\",exist_ok=True)\n#     tensorboard = TensorBoard(log_dir=os.path.join('./logs'), histogram_freq=0,\n#                                 write_graph=True, write_images=False,profile_batch = 100000000)\n\n#     callbacks = [tensorboard]\n\n    history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE) # , callbacks=callbacks\n    return history",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": true,
        "execution_millis": 61,
        "source_hash": "b1cf47d1",
        "tags": [],
        "cell_id": "00020-1d73cec6-4b76-4768-a8c6-6f92e32270a5",
        "deepnote_cell_type": "code"
      },
      "source": "history = train_model(X_train_vect, y_train, EPOCHS = 10, BATCH_SIZE = 128, patience=5)",
      "execution_count": 40,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\nEpoch 1/10\n"
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": " TypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 247, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 135, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 504, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 504, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 503, in slice_array\n    contiguous=contiguous)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\", line 53, in slice_arrays\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\", line 53, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\", line 53, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_1486]\n\nFunction call stack:\ntrain_function\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-7c73cdaa7f30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-c06e3c535893>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X_train, y_train, EPOCHS, BATCH_SIZE, patience)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     callbacks = [tensorboard]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# , callbacks=callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  TypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 247, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py\", line 135, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 620, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 504, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 504, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\", line 503, in slice_array\n    contiguous=contiguous)\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\", line 53, in slice_arrays\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\", line 53, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\", line 53, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_1486]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Analyse des rÃ©sultats",
      "metadata": {
        "tags": [],
        "cell_id": "00021-260c513f-21d8-452b-beef-2d631acdbf61",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": true,
        "source_hash": "fe2a7821",
        "tags": [],
        "cell_id": "00022-e5b294a1-4805-45e9-9731-26a6e3824ff5",
        "deepnote_cell_type": "code"
      },
      "source": "y_test_pred = model.predict_classes(X_test_vect)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": true,
        "source_hash": "96960f07",
        "tags": [],
        "cell_id": "00023-2ebfaea5-314f-4416-ac67-a800cb6f1634",
        "deepnote_cell_type": "code"
      },
      "source": "from sklearn.metrics import confusion_matrix\n\ncf_matrix = confusion_matrix(y_test, y_test_pred)\nprint(cf_matrix)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deepnote_to_be_reexecuted": true,
        "source_hash": "a69e652c",
        "tags": [],
        "cell_id": "00024-aca6003d-0a5b-434b-a36e-a5cdaf07c1d7",
        "deepnote_cell_type": "code"
      },
      "source": "import seaborn as sns\nsns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues')",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e80043e2-6875-4b65-a196-a0ffb97a1282' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "82732e20-c64e-40d8-ba3b-d51b28a2434e",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  }
}