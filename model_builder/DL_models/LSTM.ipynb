{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00000-3b05a09b-6529-438d-aa07-369ebb61628c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Activation, Conv1D, Flatten\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-48966c20-e10b-4d94-856c-c621e3ed118e",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Load w2v model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00002-a9dc273a-1c3b-43b4-9f92-cd1172f836cf",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# with open('../../data/w2v_pretrained_weights.pickle', 'rb') as handle:\n",
    "#     w2v_model = pickle.load(handle)\n",
    "with open('../../data/x_train.pickle', 'rb') as handle:\n",
    "    X_train = pickle.load(handle)\n",
    "with open('../../data/y_train.pickle', 'rb') as handle:\n",
    "    y_train = pickle.load(handle)\n",
    "with open('../../data/x_val.pickle', 'rb') as handle:\n",
    "    X_val = pickle.load(handle)\n",
    "with open('../../data/y_val.pickle', 'rb') as handle:\n",
    "    y_val = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00003-3d091541-e3c3-4a5a-a364-50b3ef443811",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# pretrained_weights = w2v_model.wv.syn0\n",
    "# vocab_size, embedding_size = pretrained_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-1dc61698-163e-4299-b35a-5105f14bfe0a",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Tokenization & Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00005-c22c5933-dbb4-43bf-b492-a0142d1a0adf",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00006-0e2e67a8-b40d-4b6d-8095-836d212dacc6",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the input: 52019\n",
      "Length of longest sentence in input: 4178\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "input_tokenizer.fit_on_texts(X_train['answer'])\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(X_train['answer'])\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Length of longest sentence in input: %g\" % max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00007-79267c43-9d49-4211-b480-902fa761e766",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_sequences.shape: (30000, 4178)\n",
      "encoder_input_sequences[172]: [   0    0    0 ...   35   89 2983]\n"
     ]
    }
   ],
   "source": [
    "x_train_pad = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "# x_train_pad = pad_sequences(input_integer_seq, maxlen=MAX_SEQ_LEN)\n",
    "print(\"encoder_input_sequences.shape:\", x_train_pad.shape)\n",
    "print(\"encoder_input_sequences[172]:\", x_train_pad[72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00008-f2d53a54-294d-46aa-aa0b-8fe1a7c9b82b",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_sequences.shape: (14000, 4178)\n",
      "encoder_input_sequences[172]: [  0   0   0 ...  58 181 386]\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "input_tokenizer.fit_on_texts(X_val['answer'])\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(X_val['answer'])\n",
    "x_val_pad = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences.shape:\", x_val_pad.shape)\n",
    "print(\"encoder_input_sequences[172]:\", x_val_pad[72])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-61b7dd4b-64f1-4095-993a-08859c661ac0",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00010-25a5d289-28af-4efc-b1fb-f28ab849db80",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "sentences = [[word for word in document.lower().split()] for document in X_train['answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00011-8af6a32e-bcc5-4141-830b-55baee1830ec",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "phrases = Phrases(sentences)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = Word2Vec(sentences, size=200, min_count = 1, window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00012-3a9c90e1-9107-47e6-ab16-92eb7fb10a1d",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = word_model.wv.syn0\n",
    "vocab_size, embedding_size = pretrained_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00013-abc5eac2-fb24-418b-91d4-f2907b61c669",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size,embedding_size,pretrained_weights):\n",
    "    \n",
    "           \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=embedding_size, \n",
    "                        weights=[pretrained_weights],\n",
    "                        input_length=max_input_len\n",
    "                       ))\n",
    "\n",
    "    model.add(LSTM(units=embedding_size))\n",
    "    model.add(Dense(units=vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "00014-e00ea810-3a78-4d3f-97ec-64583e958ada",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    mae = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    model.compile(loss=mae,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['mean_squared_error', 'mean_absolute_error']\n",
    "                  )\n",
    "    return  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "00015-f7bc8a26-b8ba-4ab7-882f-d22ebedf386d",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def fit_model( x_train, y_train, x_val, y_val, model, batch_size,  epochs = 5):\n",
    "    \n",
    "    print('Train...')\n",
    "    os.makedirs(\"./logs/LSTM_logs\",exist_ok=True)\n",
    "    tensorboard = TensorBoard(log_dir=os.path.join('./logs/LSTM_logs'), histogram_freq=0,\n",
    "                                  write_graph=True, write_images=False,profile_batch = 100000000)\n",
    "\n",
    "    Es= EarlyStopping(monitor='loss', patience=2)\n",
    "    \n",
    "    callbacks = [Es, tensorboard]\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_val, y_val),\n",
    "              callbacks= callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00016-a2cdd24d-55d9-479c-a7d6-f4bf89cb9628",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 4178, 200)         11897600  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 59488)             11957088  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 59488)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 59489     \n",
      "=================================================================\n",
      "Total params: 24,234,977\n",
      "Trainable params: 24,234,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Epoch 1/3\n",
      "600/600 [==============================] - 3835s 6s/step - loss: 67771.1025 - mean_squared_error: 10856.5130 - mean_absolute_error: 13.1588 - val_loss: 3450.8728 - val_mean_squared_error: 4957.9404 - val_mean_absolute_error: 12.1338\n",
      "Epoch 2/3\n",
      "600/600 [==============================] - 3184s 5s/step - loss: 50725.7892 - mean_squared_error: 7367.8420 - mean_absolute_error: 11.7935 - val_loss: 14732.8477 - val_mean_squared_error: 4957.9272 - val_mean_absolute_error: 12.1338\n",
      "Epoch 3/3\n",
      "306/600 [==============>...............] - ETA: 22:11 - loss: 61898.6755 - mean_squared_error: 17814.9753 - mean_absolute_error: 14.2936"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    model = build_model(vocab_size, embedding_size, pretrained_weights)\n",
    "    model.summary()\n",
    "    model = compile_model(model)\n",
    "    model = fit_model(x_train_pad, y_train, x_val_pad, y_val, model, batch_size=50, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00017-cba7ac61-6fce-43ea-9483-90ffbb07d1e7",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('./saved_model/LSTM_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00018-bfd1fcda-e056-49ef-971e-52a973b18ec9",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "loss, mean_squared_error, mean_ab = model.evaluate(x_val_pad, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00019-c554803d-c70a-460b-ac9c-aff0a6455de1",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# © Laëtitia CONSTANTIN 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e80043e2-6875-4b65-a196-a0ffb97a1282' target=\"_blank\">\n",
    "<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "10e2c8c1-3941-4d52-a57c-c2cc8bec4df5",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
