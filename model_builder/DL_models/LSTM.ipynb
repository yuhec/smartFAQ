{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00000-3b05a09b-6529-438d-aa07-369ebb61628c",
        "deepnote_cell_type": "code"
      },
      "source": "import pickle\nimport tensorflow as tf\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Input, Embedding, LSTM, Dense, Activation, Conv1D, Flatten\n\nfrom tensorflow.keras.callbacks import TensorBoard\n\nimport os",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Load w2v model & Data",
      "metadata": {
        "cell_id": "00001-48966c20-e10b-4d94-856c-c621e3ed118e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00002-a9dc273a-1c3b-43b4-9f92-cd1172f836cf",
        "deepnote_cell_type": "code"
      },
      "source": "# with open('../../data/w2v_pretrained_weights.pickle', 'rb') as handle:\n#     w2v_model = pickle.load(handle)\nwith open('../../data/x_train.pickle', 'rb') as handle:\n    X_train = pickle.load(handle)\nwith open('../../data/y_train.pickle', 'rb') as handle:\n    y_train = pickle.load(handle)\nwith open('../../data/x_val.pickle', 'rb') as handle:\n    X_val = pickle.load(handle)\nwith open('../../data/y_val.pickle', 'rb') as handle:\n    y_val = pickle.load(handle)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00003-3d091541-e3c3-4a5a-a364-50b3ef443811",
        "deepnote_cell_type": "code"
      },
      "source": "# pretrained_weights = w2v_model.wv.syn0\n# vocab_size, embedding_size = pretrained_weights.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Tokenization & Padding",
      "metadata": {
        "cell_id": "00004-1dc61698-163e-4299-b35a-5105f14bfe0a",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00005-c22c5933-dbb4-43bf-b492-a0142d1a0adf",
        "deepnote_cell_type": "code"
      },
      "source": "MAX_NUM_WORDS = 20000",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00006-0e2e67a8-b40d-4b6d-8095-836d212dacc6",
        "deepnote_cell_type": "code"
      },
      "source": "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\ninput_tokenizer.fit_on_texts(X_train['answer'])\ninput_integer_seq = input_tokenizer.texts_to_sequences(X_train['answer'])\n\nword2idx_inputs = input_tokenizer.word_index\nprint('Total unique words in the input: %s' % len(word2idx_inputs))\n\nmax_input_len = max(len(sen) for sen in input_integer_seq)\nprint(\"Length of longest sentence in input: %g\" % max_input_len)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Total unique words in the input: 30369\nLength of longest sentence in input: 1688\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00007-79267c43-9d49-4211-b480-902fa761e766",
        "deepnote_cell_type": "code"
      },
      "source": "x_train_pad = pad_sequences(input_integer_seq, maxlen=max_input_len)\n# x_train_pad = pad_sequences(input_integer_seq, maxlen=MAX_SEQ_LEN)\nprint(\"encoder_input_sequences.shape:\", x_train_pad.shape)\nprint(\"encoder_input_sequences[172]:\", x_train_pad[72])",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "encoder_input_sequences.shape: (10000, 1688)\nencoder_input_sequences[172]: [  0   0   0 ... 135 183  86]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00008-f2d53a54-294d-46aa-aa0b-8fe1a7c9b82b",
        "deepnote_cell_type": "code"
      },
      "source": "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\ninput_tokenizer.fit_on_texts(X_val['answer'])\ninput_integer_seq = input_tokenizer.texts_to_sequences(X_val['answer'])\nx_val_pad = pad_sequences(input_integer_seq, maxlen=max_input_len)\nprint(\"encoder_input_sequences.shape:\", x_val_pad.shape)\nprint(\"encoder_input_sequences[172]:\", x_val_pad[72])",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "encoder_input_sequences.shape: (10000, 1688)\nencoder_input_sequences[172]: [   0    0    0 ... 5837 5419 5838]\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "## Keras Model",
      "metadata": {
        "cell_id": "00009-61b7dd4b-64f1-4095-993a-08859c661ac0",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00010-25a5d289-28af-4efc-b1fb-f28ab849db80",
        "deepnote_cell_type": "code"
      },
      "source": "from gensim.models import Word2Vec\nsentences = [[word for word in document.lower().split()] for document in X_train['answer']]\n\nword_model = Word2Vec(sentences, size=200, min_count = 1, window = 5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00011-8af6a32e-bcc5-4141-830b-55baee1830ec",
        "deepnote_cell_type": "code"
      },
      "source": "# sentences",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00012-3a9c90e1-9107-47e6-ab16-92eb7fb10a1d",
        "deepnote_cell_type": "code"
      },
      "source": "pretrained_weights = word_model.wv.syn0\nvocab_size, embedding_size = pretrained_weights.shape",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n  \"\"\"Entry point for launching an IPython kernel.\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00013-abc5eac2-fb24-418b-91d4-f2907b61c669",
        "deepnote_cell_type": "code"
      },
      "source": "def build_model(vocab_size,embedding_size,pretrained_weights):\n    \n           \n    model = tf.keras.Sequential()\n    \n    model.add(Embedding(input_dim=vocab_size, \n                        output_dim=embedding_size, \n                        weights=[pretrained_weights],\n                        input_length=max_input_len\n                       ))\n\n    model.add(LSTM(units=embedding_size))\n    model.add(Dense(units=vocab_size))\n    model.add(Activation('softmax'))\n    model.add(Dense(1))\n\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00014-e00ea810-3a78-4d3f-97ec-64583e958ada",
        "deepnote_cell_type": "code"
      },
      "source": "def compile_model(model):\n    mse = tf.keras.losses.MeanSquaredError()\n    model.compile(loss=mse,\n                  optimizer='adam',\n                  metrics=['MeanSquaredError']\n                  )\n    return  model",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00015-f7bc8a26-b8ba-4ab7-882f-d22ebedf386d",
        "deepnote_cell_type": "code"
      },
      "source": "def fit_model( x_train, y_train, x_val, y_val, model, batch_size,  epochs = 5):\n    \n    print('Train...')\n    os.makedirs(\"./logs\",exist_ok=True)\n    tensorboard = TensorBoard(log_dir=os.path.join('./logs'), histogram_freq=0,\n                                  write_graph=True, write_images=False,profile_batch = 100000000)\n\n    callbacks = [ tensorboard]\n\n    model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_val, y_val),\n              callbacks= callbacks)\n    return model",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00016-a2cdd24d-55d9-479c-a7d6-f4bf89cb9628",
        "deepnote_cell_type": "code"
      },
      "source": "with tf.device(\"/CPU:0\"):\n    model = build_model(vocab_size, embedding_size, pretrained_weights)\n    model.summary()\n    model = compile_model(model)\n    model = fit_model(x_train_pad, y_train, x_val_pad, y_val, model, batch_size=200, epochs=10)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 1688, 200)         6074000   \n_________________________________________________________________\nconv1d (Conv1D)              (None, 1684, 128)         128128    \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 1680, 128)         82048     \n_________________________________________________________________\nflatten (Flatten)            (None, 215040)            0         \n_________________________________________________________________\ndense (Dense)                (None, 10)                2150410   \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 11        \n=================================================================\nTotal params: 8,434,597\nTrainable params: 8,434,597\nNon-trainable params: 0\n_________________________________________________________________\nTrain...\nEpoch 1/10\n50/50 [==============================] - 128s 3s/step - loss: 188.2514 - mean_squared_error: 188.2514 - val_loss: 142.9084 - val_mean_squared_error: 142.9084\nEpoch 2/10\n50/50 [==============================] - 124s 2s/step - loss: 132.6154 - mean_squared_error: 132.6154 - val_loss: 142.9084 - val_mean_squared_error: 142.9084\nEpoch 3/10\n50/50 [==============================] - 125s 3s/step - loss: 126.4466 - mean_squared_error: 126.4466 - val_loss: 142.9084 - val_mean_squared_error: 142.9084\nEpoch 4/10\n50/50 [==============================] - 126s 3s/step - loss: 121.7370 - mean_squared_error: 121.7370 - val_loss: 142.9084 - val_mean_squared_error: 142.9084\nEpoch 5/10\n50/50 [==============================] - 125s 3s/step - loss: 195.1155 - mean_squared_error: 195.1155 - val_loss: 142.9084 - val_mean_squared_error: 142.9084\nEpoch 6/10\n50/50 [==============================] - 125s 3s/step - loss: 306.1377 - mean_squared_error: 306.1377 - val_loss: 142.9084 - val_mean_squared_error: 142.9084\nEpoch 7/10\n50/50 [==============================] - 125s 3s/step - loss: 106.7103 - mean_squared_error: 106.7103 - val_loss: 142.9084 - val_mean_squared_error: 142.9084\nEpoch 8/10\n50/50 [==============================] - 125s 3s/step - loss: 131.3567 - mean_squared_error: 131.3567 - val_loss: 142.9084 - val_mean_squared_error: 142.9084\nEpoch 9/10\n50/50 [==============================] - 122s 2s/step - loss: 175.7063 - mean_squared_error: 175.7063 - val_loss: 142.9084 - val_mean_squared_error: 142.9084\nEpoch 10/10\n50/50 [==============================] - 121s 2s/step - loss: 159.7663 - mean_squared_error: 159.7663 - val_loss: 142.9084 - val_mean_squared_error: 142.9084\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00017-cba7ac61-6fce-43ea-9483-90ffbb07d1e7",
        "deepnote_cell_type": "code"
      },
      "source": "# Save the entire model as a SavedModel.\n!mkdir -p saved_model\nmodel.save('./saved_model/LSTM_model')",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "INFO:tensorflow:Assets written to: ./saved_model/CNN_model/assets\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cell_id": "00018-bfd1fcda-e056-49ef-971e-52a973b18ec9",
        "deepnote_cell_type": "code"
      },
      "source": "(loss, acc) = model.evaluate(x_val_pad, y_val)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "313/313 [==============================] - 23s 72ms/step - loss: 142.9084 - mean_squared_error: 142.9084\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# © Laëtitia CONSTANTIN 2021",
      "metadata": {
        "tags": [],
        "cell_id": "00019-c554803d-c70a-460b-ac9c-aff0a6455de1",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e80043e2-6875-4b65-a196-a0ffb97a1282' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 4,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "deepnote_notebook_id": "10e2c8c1-3941-4d52-a57c-c2cc8bec4df5",
    "deepnote": {},
    "deepnote_execution_queue": []
  }
}