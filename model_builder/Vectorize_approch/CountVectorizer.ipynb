{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-0be5ab94-9b51-4b57-9161-dc0757b5f142",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "2a169a4",
        "execution_millis": 11,
        "execution_start": 1616159846004,
        "deepnote_cell_type": "code"
      },
      "source": "import pandas as pd\nimport numpy as np\nimport pickle\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import TweetTokenizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestRegressor",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-f2551186-0a25-40d7-ae1a-87b2f42f3d26",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "4f3b8700",
        "execution_millis": 82,
        "execution_start": 1616160253418,
        "deepnote_cell_type": "code"
      },
      "source": "with open('../../data/x_train.pickle', 'rb') as handle:\n    X_train = pickle.load(handle)\nwith open('../../data/y_train.pickle', 'rb') as handle:\n    y_train = pickle.load(handle)\nwith open('../../data/x_val.pickle', 'rb') as handle:\n    X_val = pickle.load(handle)\nwith open('../../data/y_val.pickle', 'rb') as handle:\n    y_val = pickle.load(handle)",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-1d17b60a-99d2-4bef-8592-d15d30f02e63",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "7c234d23",
        "execution_millis": 35,
        "execution_start": 1616069926460,
        "deepnote_cell_type": "code"
      },
      "source": "X_train.head()",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "application/vnd.deepnote.dataframe.v2+json": {
              "row_count": 5,
              "column_count": 4,
              "columns": [
                {
                  "name": "id",
                  "dtype": "int64",
                  "stats": {
                    "unique_count": 5,
                    "nan_count": 0,
                    "min": 2185875,
                    "max": 34022443,
                    "histogram": [
                      {
                        "bin_start": 2185875,
                        "bin_end": 5369531.8,
                        "count": 1
                      },
                      {
                        "bin_start": 5369531.8,
                        "bin_end": 8553188.6,
                        "count": 1
                      },
                      {
                        "bin_start": 8553188.6,
                        "bin_end": 11736845.399999999,
                        "count": 0
                      },
                      {
                        "bin_start": 11736845.399999999,
                        "bin_end": 14920502.2,
                        "count": 1
                      },
                      {
                        "bin_start": 14920502.2,
                        "bin_end": 18104159,
                        "count": 0
                      },
                      {
                        "bin_start": 18104159,
                        "bin_end": 21287815.799999997,
                        "count": 1
                      },
                      {
                        "bin_start": 21287815.799999997,
                        "bin_end": 24471472.599999998,
                        "count": 0
                      },
                      {
                        "bin_start": 24471472.599999998,
                        "bin_end": 27655129.4,
                        "count": 0
                      },
                      {
                        "bin_start": 27655129.4,
                        "bin_end": 30838786.2,
                        "count": 0
                      },
                      {
                        "bin_start": 30838786.2,
                        "bin_end": 34022443,
                        "count": 1
                      }
                    ]
                  }
                },
                {
                  "name": "question",
                  "dtype": "object",
                  "stats": {
                    "unique_count": 5,
                    "nan_count": 0,
                    "categories": [
                      {
                        "name": "Deleting multiple indexes list python",
                        "count": 1
                      },
                      {
                        "name": "Django Grappelli Nested Inlines create new nested lines initial load",
                        "count": 1
                      },
                      {
                        "name": "3 others",
                        "count": 3
                      }
                    ]
                  }
                },
                {
                  "name": "question_body",
                  "dtype": "object",
                  "stats": {
                    "unique_count": 5,
                    "nan_count": 0,
                    "categories": [
                      {
                        "name": "My problem I list eg lst lst pop lst pop Because lst removed lst longer range This gives error Now I know could say change code lst pop lst pop ill fix error problem actual code 'popping ' random numbers needs done time avoid error Is method 'popping ' time like something similar lst pop Thanks answers",
                        "count": 1
                      },
                      {
                        "name": "I looking way create new nested row saving owner row By way django ticket I found Grappelli Nested Inlines I using I test project set based instructions found link django contrib import admin grappelli nested admin import NestedModelAdmin NestedStackedInline NestedTabularInline models import class MyNestedInline NestedTabularInline model C extra class MyInline NestedStackedInline model B extra inlines MyNestedInline class MyAdmin NestedModelAdmin inlines MyInline admin site register A MyAdmin My issue based fact I create child object saving parent That say add another c button functionality saving B Is way achieve I read posts regarding I could find I say answer included anywhere I understand please patient I also note production code grappelli requirement anything clashes work",
                        "count": 1
                      },
                      {
                        "name": "3 others",
                        "count": 3
                      }
                    ]
                  }
                },
                {
                  "name": "answer",
                  "dtype": "object",
                  "stats": {
                    "unique_count": 5,
                    "nan_count": 0,
                    "categories": [
                      {
                        "name": "You use list comprehension rebuild list indices newlist v v enumerate oldlist indices I used set indices set membership testing faster list Note delete best done del lst index partially rebuilds list well one loop list comprehension efficient Demo gt gt gt oldlist gt gt gt indices gt gt gt v v enumerate oldlist indices",
                        "count": 1
                      },
                      {
                        "name": "What take templates django grappelli inline provides use use template django nested inlines class NestedStackedInline NestedInline template 'admin edit inline stacked html ' class NestedTabularInline NestedInline template 'admin edit inline tabular html ' Where templates ones django grappelli inline",
                        "count": 1
                      },
                      {
                        "name": "3 others",
                        "count": 3
                      }
                    ]
                  }
                },
                {
                  "name": "_deepnote_index_column",
                  "dtype": "int64"
                }
              ],
              "rows_top": [
                {
                  "id": 21032057,
                  "question": "Deleting multiple indexes list python",
                  "question_body": "My problem I list eg lst lst pop lst pop Because lst removed lst longer range This gives error Now I know could say change code lst pop lst pop ill fix error problem actual code 'popping ' random numbers needs done time avoid error Is method 'popping ' time like something similar lst pop Thanks answers",
                  "answer": "You use list comprehension rebuild list indices newlist v v enumerate oldlist indices I used set indices set membership testing faster list Note delete best done del lst index partially rebuilds list well one loop list comprehension efficient Demo gt gt gt oldlist gt gt gt indices gt gt gt v v enumerate oldlist indices",
                  "_deepnote_index_column": 490144
                },
                {
                  "id": 34022443,
                  "question": "Django Grappelli Nested Inlines create new nested lines initial load",
                  "question_body": "I looking way create new nested row saving owner row By way django ticket I found Grappelli Nested Inlines I using I test project set based instructions found link django contrib import admin grappelli nested admin import NestedModelAdmin NestedStackedInline NestedTabularInline models import class MyNestedInline NestedTabularInline model C extra class MyInline NestedStackedInline model B extra inlines MyNestedInline class MyAdmin NestedModelAdmin inlines MyInline admin site register A MyAdmin My issue based fact I create child object saving parent That say add another c button functionality saving B Is way achieve I read posts regarding I could find I say answer included anywhere I understand please patient I also note production code grappelli requirement anything clashes work",
                  "answer": "What take templates django grappelli inline provides use use template django nested inlines class NestedStackedInline NestedInline template 'admin edit inline stacked html ' class NestedTabularInline NestedInline template 'admin edit inline tabular html ' Where templates ones django grappelli inline",
                  "_deepnote_index_column": 815071
                },
                {
                  "id": 2185875,
                  "question": "Expanding elements list",
                  "question_body": "I 'm looking nice way process list elements need expanded elements expansion results Standard iterative way would lt len l needs expanding l new expand l l new len new else pretty ugly I could rewrite contents new list nl x l needs expanding x nl expand x else nl append x But seem long Or I could simply passes flatten list later flatten expand x needs expanding x else x x l def try expanding x flatten try expanding x x l n't feel right either Are clear ways",
                  "answer": "The last one probably pythonic could try implied loop py generator map flatten map lambda x expand x needs expanding x else x l flatten map try expanding l",
                  "_deepnote_index_column": 62146
                },
                {
                  "id": 12626260,
                  "question": "UnicodeDecodeError processing filenames",
                  "question_body": "I 'm using Python Ubuntu x I files folder filesystem The file names files contain html encoded escaped characters files originally downloaded website Here examples Jamaica jpg thai trip E B E B E A A E B F RAY jpg I wrote simple Python script goes folder renames files encoded characters filename The new filename achieved simply decoding string makes filename The script works files files Python chokes spits following error UnicodeDecodeError 'ascii ' codec ca n't decode byte xe position ordinal range Traceback recent call last File download py line downloadGalleries numDownloaded downloadGallery opener galleryLink File download py line downloadGallery filePathPrefix getFilePath content File download py line getFilePath return cleanupString match group strip ' ' cleanupString match group strip File home abc XYZ common py line cleanupString return HTMLParser HTMLParser unescape string File usr lib python HTMLParser py line unescape return sub r amp xX fA F w replaceEntities File usr lib python py line sub return compile pattern flags sub repl string count Here contents cleanupString function def cleanupString string string urllib unquote string return HTMLParser HTMLParser unescape string And 's snippet code calls cleanupString function code code traceback produces error rootFolder sys argv pattern r ' jpg jpeg ' reobj compile pattern IGNORECASE imgs root dirs files os walk rootFolder filename files foundFile os path join root filename reobj match foundFile imgs append foundFile img imgs print 'Checking file ' img newImg cleanupString img Code blows files Can anyone provide way get around error I 've already tried adding coding utf top script effect Thanks",
                  "answer": "Your filenames byte strings contain UTF bytes representing unicode characters The HTML parser normally works unicode data instead byte strings particularly encounters ampersand escape Python automatically trying decode value default uses ASCII decoding This fails UTF data contains bytes fall outside ASCII range You need explicitly decode string unicode object def cleanupString string string urllib unquote string decode 'utf ' return HTMLParser HTMLParser unescape string Your next problem unicode filenames filesystem need kind encoding work filenames You check encoding sys getfilesystemencoding use encode filenames def cleanupString string string urllib unquote string decode 'utf ' return HTMLParser HTMLParser unescape string encode sys getfilesystemencoding You read Python deals Unicode Unicode HOWTO",
                  "_deepnote_index_column": 304024
                },
                {
                  "id": 7288407,
                  "question": "Python string manipulation performance problems",
                  "question_body": "I following piece code I execute around million times application parse many records This part seems bottleneck I wondering anyone could help suggesting nifty tricks could make simple string manipulations faster try data start end info self Columns end start info columnLength slice line start end slice `` len slice info columnLength raise 'Wrong Input ' info hasSignage slice strip ' ' slice strip ' ' raise 'Wrong Input ' info skipColumn data append slice start end parsedLine data except parsedLine False",
                  "answer": "EDIT I 'm changing answer bit I 'll leave original answer In answer I commented best thing would find built Python module would unpacking I could n't think one perhaps I Google searched one John Machin provided answer showed use Python struct module Since written C faster pure Python solution I n't actually measured anything guess I agree logic original code un Pythonic Returning sentinel value n't best 's better either return valid value raise exception The way return list valid values plus another list invalid values Since John Machin offered code yield valid values I thought I 'd write version returns two lists NOTE Perhaps best possible answer would take John Machin 's answer modify save invalid values file possible later review His answer yields answers one time need build large list parsed records saving bad lines disk means need build possibly large list bad lines import struct def parse records self returns tuple good bad good list valid records tuples bad list tuples line num line err cols self Columns unpack fmt sign checks start colx info enumerate cols clen info columnLength clen lt raise ValueError Column Bad columnLength r colx clen info skipColumn unpack fmt str clen x else unpack fmt str clen info hasSignage sign checks append start start clen expected len start unpack struct Struct unpack fmt unpack good bad line num line enumerate self whatever list lines len line expected len bad append line num line bad length continue line ' ' sign checks bad append line num line sign check failed continue good append unpack line return good bad ORIGINAL ANSWER TEXT This answer lot faster self Columns information identical records We processing self Columns information one time build couple lists contain need process record This code shows compute parsedList n't actually yield return anything Obviously would need change def parse records self cols self Columns slices sign checks start info cols info columnLength lt raise ValueError bad columnLength end start info columnLength info skipColumn tup start end slices append tup info hasSignage sign checks append start expected len end use end count newline try line self whatever list lines len line expected len raise ValueError wrong length line ' ' sign checks raise ValueError wrong input parsedLine line e e slices except ValueError parsedLine False",
                  "_deepnote_index_column": 187856
                }
              ],
              "rows_bottom": null
            },
            "text/plain": "              id                                           question  \\\n490144  21032057              Deleting multiple indexes list python   \n815071  34022443  Django Grappelli Nested Inlines create new nes...   \n62146    2185875                            Expanding elements list   \n304024  12626260            UnicodeDecodeError processing filenames   \n187856   7288407    Python string manipulation performance problems   \n\n                                            question_body  \\\n490144  My problem I list eg lst lst pop lst pop Becau...   \n815071  I looking way create new nested row saving own...   \n62146   I 'm looking nice way process list elements ne...   \n304024  I 'm using Python Ubuntu x I files folder file...   \n187856  I following piece code I execute around millio...   \n\n                                                   answer  \n490144  You use list comprehension rebuild list indice...  \n815071  What take templates django grappelli inline pr...  \n62146   The last one probably pythonic could try impli...  \n304024  Your filenames byte strings contain UTF bytes ...  \n187856  EDIT I 'm changing answer bit I 'll leave orig...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>question</th>\n      <th>question_body</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>490144</th>\n      <td>21032057</td>\n      <td>Deleting multiple indexes list python</td>\n      <td>My problem I list eg lst lst pop lst pop Becau...</td>\n      <td>You use list comprehension rebuild list indice...</td>\n    </tr>\n    <tr>\n      <th>815071</th>\n      <td>34022443</td>\n      <td>Django Grappelli Nested Inlines create new nes...</td>\n      <td>I looking way create new nested row saving own...</td>\n      <td>What take templates django grappelli inline pr...</td>\n    </tr>\n    <tr>\n      <th>62146</th>\n      <td>2185875</td>\n      <td>Expanding elements list</td>\n      <td>I 'm looking nice way process list elements ne...</td>\n      <td>The last one probably pythonic could try impli...</td>\n    </tr>\n    <tr>\n      <th>304024</th>\n      <td>12626260</td>\n      <td>UnicodeDecodeError processing filenames</td>\n      <td>I 'm using Python Ubuntu x I files folder file...</td>\n      <td>Your filenames byte strings contain UTF bytes ...</td>\n    </tr>\n    <tr>\n      <th>187856</th>\n      <td>7288407</td>\n      <td>Python string manipulation performance problems</td>\n      <td>I following piece code I execute around millio...</td>\n      <td>EDIT I 'm changing answer bit I 'll leave orig...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-4303b8f8-e076-45df-afb1-61fed8650530",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ce17a20c",
        "execution_millis": 453,
        "execution_start": 1616069926488,
        "deepnote_cell_type": "code"
      },
      "source": "nltk.download('stopwords')\nnltk.download('punkt')\nprint(stopwords.words('english'))",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-15b16ea4-a93f-41db-aae7-7e61912bd1a7",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b457e22c",
        "execution_millis": 0,
        "execution_start": 1616069926913,
        "deepnote_cell_type": "code"
      },
      "source": "def tokenizer_cleaning(sentence):\n    text_tokens = nltk.word_tokenize(sentence)\n    token_without_sw = [word for word in text_tokens if not word in stopwords.words()]   \n    return token_without_sw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00004-91455e99-ab99-4299-bc12-09cc49a2f222",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "18f8a5a1",
        "execution_millis": 1,
        "execution_start": 1616069926923,
        "deepnote_cell_type": "code"
      },
      "source": "ngram_size = 5\nvectorizer = CountVectorizer(ngram_range = (ngram_size, ngram_size),analyzer = tokenizer_cleaning)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00005-3fb54b93-4fc5-43df-bf98-a923757d9e2b",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "75eff4d3",
        "execution_millis": 4072679,
        "execution_start": 1616069926924,
        "deepnote_cell_type": "code"
      },
      "source": "smart_vectorizer = vectorizer.fit_transform(X_train['question_body'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00007-92670210-027a-4637-b6e8-9c5d24793bb8",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "38800d8c",
        "execution_millis": 45,
        "execution_start": 1616073999604,
        "deepnote_cell_type": "code"
      },
      "source": "smart_vectorizer.shape",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "(10000, 54199)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "with open('../../data/smart_vectorizer_qb.pickle', 'rb') as handle:\n    smart_vectorizer = pickle.load(handle)",
      "metadata": {
        "tags": [],
        "cell_id": "00008-6ac3c730-35d5-48e0-b0a6-c0389793321c",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e7a4e95f",
        "execution_millis": 17,
        "execution_start": 1616162738077,
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOFError",
          "evalue": "Ran out of input",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-11891a193873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../data/smart_vectorizer_qb.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msmart_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
          ]
        }
      ],
      "execution_count": 47
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00008-0e0790f8-5080-4aeb-a14f-86362f64e686",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "fc0c4ee2",
        "execution_millis": 34,
        "execution_start": 1616160214994,
        "deepnote_cell_type": "code"
      },
      "source": "with open('../../data/smart_vectorizer_qb.pickle', 'wb') as handle:\n    pickle.dump(smart_vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnsupportedOperation",
          "evalue": "read",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a1524f70c9a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../data/smart_vectorizer_qb.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msmart_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmart_vectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnsupportedOperation\u001b[0m: read"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00008-8e7fb09b-91fd-42f2-bd2b-9337ee4cb449",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "1a713bde",
        "execution_millis": 3814252,
        "execution_start": 1616073999605,
        "deepnote_cell_type": "code"
      },
      "source": "vectorizer_test = vectorizer.transform(X_val['question_body'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00008-bf45d806-2c00-4e4c-9bd9-43872d7f4db3",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "d4444a5b",
        "execution_start": 1616077813857,
        "execution_millis": 1,
        "deepnote_cell_type": "code"
      },
      "source": "from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestClassifier(max_depth=50, random_state=0, n_estimators = 1000)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00009-0ec05f6d-b3b0-4916-997f-e9d6daef9e38",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "79317d09",
        "execution_start": 1616077813858,
        "deepnote_cell_type": "code"
      },
      "source": "model.fit(smart_vectorizer, X_train['question_body'])",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KernelInterrupted",
          "evalue": "Execution interrupted by the Jupyter kernel.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00011-074191f6-d5f8-4f73-85b6-29e39ff7d75b",
        "deepnote_to_be_reexecuted": true,
        "source_hash": "3c47113f",
        "deepnote_cell_type": "code"
      },
      "source": "y_pred = model.predict(vectorizer_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# © Mouna DAHAMANI 2021",
      "metadata": {
        "tags": [],
        "cell_id": "00014-ec3ae2c1-70cd-4fd3-a92a-e7c25ca3b28c",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e80043e2-6875-4b65-a196-a0ffb97a1282' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote_notebook_id": "8d389152-0510-41c5-b414-57c03a355d16",
    "deepnote": {},
    "deepnote_execution_queue": []
  }
}