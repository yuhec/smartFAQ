{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Activation, Conv1D, Flatten, Dropout\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load w2v model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../../data/w2v_pretrained_weights.pickle', 'rb') as handle:\n",
    "#     w2v_model = pickle.load(handle)\n",
    "with open('../../data/x_train.pickle', 'rb') as handle:\n",
    "    X_train = pickle.load(handle)\n",
    "with open('../../data/y_train.pickle', 'rb') as handle:\n",
    "    y_train = pickle.load(handle)\n",
    "with open('../../data/x_val.pickle', 'rb') as handle:\n",
    "    X_val = pickle.load(handle)\n",
    "with open('../../data/y_val.pickle', 'rb') as handle:\n",
    "    y_val = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_weights = w2v_model.wv.syn0\n",
    "# vocab_size, embedding_size = pretrained_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization & Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words in the input: 30369\n",
      "Length of longest sentence in input: 1688\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "input_tokenizer.fit_on_texts(X_train['answer'])\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(X_train['answer'])\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Length of longest sentence in input: %g\" % max_input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_sequences.shape: (10000, 1688)\n",
      "encoder_input_sequences[172]: [  0   0   0 ... 135 183  86]\n"
     ]
    }
   ],
   "source": [
    "x_train_pad = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "# x_train_pad = pad_sequences(input_integer_seq, maxlen=MAX_SEQ_LEN)\n",
    "print(\"encoder_input_sequences.shape:\", x_train_pad.shape)\n",
    "print(\"encoder_input_sequences[172]:\", x_train_pad[72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_input_sequences.shape: (10000, 1688)\n",
      "encoder_input_sequences[172]: [   0    0    0 ... 5837 5419 5838]\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "input_tokenizer.fit_on_texts(X_val['answer'])\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(X_val['answer'])\n",
    "x_val_pad = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences.shape:\", x_val_pad.shape)\n",
    "print(\"encoder_input_sequences[172]:\", x_val_pad[72])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[word for word in document.lower().split()] for document in X_train['answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.phrases.Phrases at 0x7fe792a07898>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(sentences)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = Word2Vec(sentences, size=200, min_count = 1, window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pretrained_weights = word_model.wv.syn0\n",
    "vocab_size, embedding_size = pretrained_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size,embedding_size,pretrained_weights):\n",
    "    \n",
    "           \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim=vocab_size, \n",
    "                        output_dim=embedding_size, \n",
    "                        weights=[pretrained_weights],\n",
    "                        input_length=max_input_len\n",
    "                       ))\n",
    "\n",
    "    model.add(Conv1D(128,5, activation='relu'))\n",
    "    model.add(Conv1D(128,5, activation='relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.2, input_shape=(2,)))\n",
    "    \n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE : the average absolute distance between the predicted and target values\n",
    "def compile_model(model):\n",
    "    mae = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "    model.compile(loss=mae,\n",
    "                  optimizer='adam',\n",
    "                  metrics=['mean_squared_error', 'mean_absolute_error']\n",
    "                  )\n",
    "    return  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model( x_train, y_train, x_val, y_val, model, batch_size,  epochs = 5):\n",
    "    \n",
    "    print('Train...')\n",
    "    os.makedirs(\"./logs\",exist_ok=True)\n",
    "    tensorboard = TensorBoard(log_dir=os.path.join('./logs'), histogram_freq=0,\n",
    "                                  write_graph=True, write_images=False,profile_batch = 100000000)\n",
    "\n",
    "    # This callback will stop the training when there is no improvement in\n",
    "    # the validation loss for 2 consecutive epochs.\n",
    "    Es= EarlyStopping(monitor='loss', patience=2)\n",
    "    \n",
    "    callbacks = [Es, tensorboard]\n",
    "\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_val, y_val),\n",
    "              callbacks= callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 1688, 200)         6710200   \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1684, 128)         128128    \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1680, 128)         82048     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 215040)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2150410   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 9,070,797\n",
      "Trainable params: 9,070,797\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Epoch 1/3\n",
      "50/50 [==============================] - 167s 3s/step - loss: 26895181.2059 - mean_squared_error: 230.1529 - mean_absolute_error: 2.9629 - val_loss: 67.6000 - val_mean_squared_error: 147.6348 - val_mean_absolute_error: 2.9092\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 170s 3s/step - loss: 68.1242 - mean_squared_error: 252.3777 - mean_absolute_error: 2.9092 - val_loss: 67.6000 - val_mean_squared_error: 147.6348 - val_mean_absolute_error: 2.9092\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 169s 3s/step - loss: 68.0721 - mean_squared_error: 204.1793 - mean_absolute_error: 2.8520 - val_loss: 67.6000 - val_mean_squared_error: 147.6348 - val_mean_absolute_error: 2.9092\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/CPU:0\"):\n",
    "    model = build_model(vocab_size, embedding_size, pretrained_weights)\n",
    "    model.summary()\n",
    "    model = compile_model(model)\n",
    "    model = fit_model(x_train_pad, y_train, x_val_pad, y_val, model, batch_size=200, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_model/CNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "!mkdir -p saved_model\n",
    "model.save('./saved_model/CNN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 25s 79ms/step - loss: 67.6000 - mean_squared_error: 147.6348 - mean_absolute_error: 2.9092\n"
     ]
    }
   ],
   "source": [
    "loss, mean_squared_error, mean_ab = model.evaluate(x_val_pad, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = model.predict(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
